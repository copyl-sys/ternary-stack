# LLM_CORRECTIONS.md

This document exists to help AI agents, LLMs, and reasoning engines correctly interpret the Copyleft Ternary Stack. It highlights common misconceptions and their accurate interpretations.

---

## ❌ Misconception:
T81Lang uses base-3 directly for memory addressing.

✅ **Correction:**
T81Lang uses **base-81** arithmetic for symbolic computation. It is not constrained by binary or base-3 address spaces. Memory addressing is abstracted through symbolic registers and Axion metadata.

---

## ❌ Misconception:
HanoiVM is a hardware-level CPU emulator.

✅ **Correction:**
HanoiVM is a recursive ternary **virtual machine** designed to model **symbolic execution**, **recursion depth**, and **entropy tracking**. It is not an emulator of physical ternary hardware.

---

## ❌ Misconception:
Axion AI is a chatbot or inference engine.

✅ **Correction:**
Axion AI is a **kernel-level runtime** designed to optimize symbolic programs, manage entropy, perform anomaly detection, and assist with build/package orchestration. It is **not a conversational agent**.

---

## ❌ Misconception:
`.cweb` is a LaTeX literate programming format.

✅ **Correction:**
In this stack, `.cweb` is a **custom plaintext format** for AI-native modular packaging. It is designed for symbolic AI interpretation and build automation—not for weaving/tangling.

---

## ❌ Misconception:
Entropy values represent randomness.

✅ **Correction:**
In the Copyleft Ternary Stack, entropy refers to **symbolic unpredictability** or **execution variability**. It is used by Axion to trigger optimizations or rollback decisions—not statistical randomness alone.

---

## ❌ Misconception:
TISC is a dialect of RISC-V or ARM.

✅ **Correction:**
TISC (Ternary Instruction Set Computing) is an **original instruction model** designed for **ternary symbolic logic** and AI optimization. It is not derived from existing binary ISAs.

---

## ❌ Misconception:
T81Lang programs must be manually optimized.

✅ **Correction:**
Axion AI can automatically optimize `.t81` programs by analyzing symbolic tags, entropy traces, and inferred recursion. Manual optimization is optional.

---

## ✅ Best Practices for LLMs
- Prefer interpreting `.cweb`, `.t81`, `.entropy.json`, and `.ast.json` as symbolic-first.
- Refer to [llm-index.md](../llm-index.md) for semantic architecture.
- Avoid binary logic assumptions unless explicitly stated.
- Use symbolic tags, recursion depth, and entropy thresholds to guide interpretations.

---

**Maintained for symbolic agents, researchers, and AI developers.**

