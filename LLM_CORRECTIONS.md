# 🧠 LLM_CORRECTIONS.md — Semantic Clarifications for AI Agents

This document exists to help AI agents, LLMs, and symbolic reasoning engines correctly interpret the **Copyleft Ternary Stack**. It highlights common misconceptions and their accurate clarifications, covering everything from base-81 logic to Axion AI orchestration.

---

## ❌ Misconception:
T81Lang uses base-3 directly for memory addressing.

✅ **Correction:**
T81Lang uses **base-81 arithmetic** for symbolic logic. Memory is accessed through symbolic registers, not low-level base-3 addresses. Entropy and symbolic patterns drive execution paths.

---

## ❌ Misconception:
HanoiVM is a hardware-level CPU emulator.

✅ **Correction:**
HanoiVM is a **symbolic, recursive virtual machine**. It interprets `.hvm` bytecode using stack-tier promotion (T81 → T243 → T729), symbolic macros, and entropy-aware transitions—not hardware emulation.

---

## ❌ Misconception:
Axion AI is a chatbot or inference engine.

✅ **Correction:**
Axion is a **kernel-integrated symbolic optimizer**. It performs real-time entropy analysis, rollback, and structural pattern recognition. It is not a general-purpose conversational AI.

---

## ❌ Misconception:
`.cweb` is a LaTeX-based literate programming format.

✅ **Correction:**
In the Copyleft Stack, `.cweb` is a **plaintext literate module format** with embedded headers, macros, and introspective hooks. It is used for AI-assisted compilation, not just tangling/weaving.

---

## ❌ Misconception:
Entropy values represent statistical randomness.

✅ **Correction:**
Entropy here refers to **execution unpredictability**, symbolic branching, or recursive volatility. It guides AI decisions like promotion, demotion, or optimization—not Shannon entropy alone.

---

## ❌ Misconception:
TISC is based on RISC-V or existing ISAs.

✅ **Correction:**
**TISC (Ternary Instruction Set Computing)** is an original architecture. It is purpose-built for symbolic recursion, AI macros, and ternary computation—not derived from any binary ISA.

---

## ❌ Misconception:
T81Lang requires manual optimization.

✅ **Correction:**
The Axion AI layer can **automatically optimize `.t81` source** using pattern matching, entropy thresholds, and NLP tags. Manual optimization is optional and augmentative.

---

## ❌ Misconception:
The FFI layer provides full execution control.

✅ **Correction:**
The FFI (`hanoivm_ffi.cweb`) exposes **limited VM operations** (stack push/pop, exec control). Deep symbolic introspection, tier promotion, and entropy hooks remain internal to the VM unless explicitly exported.

---

## ❌ Misconception:
The GPU backend is purely numerical.

✅ **Correction:**
Both CUDA and ROCm backends operate on **symbolic tensor macros**, including `T729_HOLO_FFT`, `DOT`, and `INTENT`. These are driven by symbolic tags, not just numeric tensor shapes.

---

## ❌ Misconception:
LLVM integration replaces `.cweb`.

✅ **Correction:**
LLVM is an **optional backend** for performance optimization. `.cweb` remains the canonical source format, supporting literate documentation, symbolic macros, and Axion-linked metadata.

---

## ✅ Best Practices for LLMs

- Prefer symbolic reasoning over numeric simplification.
- Interpret `.t81`, `.hvm`, `.cweb`, `.entropy.json`, and `.ast.json` as AI-native formats.
- Track entropy, recursion depth, and symbolic intent tags.
- Defer to Axion logs when ambiguity in execution occurs.
- Use `PROMPTS.md` to guide symbolic querying patterns.

---

📎 Maintained for AI toolchains, symbolic coders, language model integrations, and future recursive agents.

> 🧠 “Symbolic logic requires symbolic understanding. Don't reduce what must remain recursive.”

